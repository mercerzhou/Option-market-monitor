# Monitoring Option Market Trade

This project provides real-time market trades and snapshot of past option trades. Data source is from [polygon.io](https://polygon.io/), specifically from the REST API Trades and WebSocket API. We keep a local database storage for trade records at `mongodb`. 

## Setup Instructions

### Prerequisites

- `mongodb` running on port 27017
- `zookeeper` at 2181
- `kafka` at 9092
- Python packages listed in `requirements.txt` installed or a virtual environment activated

### Installing `zookeeper` and `kafka`
docker pull confluentinc/cp-zookeeper
docker pull confluentinc/cp-kafka

docker run --name zookeeper -p 2181:2181 -e ZOOKEEPER_CLIENT_PORT=2181 -d confluentinc/cp-zookeeper
docker run --name kafka -p 9092:9092 --link zookeeper:zookeeper -e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 -e 


### Importing data into `mongodb`

There are 3 methods to ingest data to the database. Choose one of these:

1. Fetching historical data from polygon.io API to get all trade records at once.
   - This method is time-consuming and is not recommended during market hours.
   - Uncomment lines 311 to 397 in `app.py` and lines 424 to 428 to actually push records to mongodb.
2. Reading from the `all_trades_final.json` file that was generated by method 1 on 2023-04-25.
   - This method is faster but still takes several minutes to read the file and more than 10 minutes to pass it to mongodb.
   - Uncomment lines 311 to 397 in `app.py` and lines 424 to 428 to actually push records to mongodb.
3. Importing the `all_trades_final.json` file using `mongodb compass`.
   - Start a database called `APAN5400Proj` and a collection inside called `Trades`.
   - Choose 'import from json or csv file' and select the `all_trades_final.json` file.
   - This is the most visually convenient method and allows you to monitor the progress bar while the file is being imported.

After you have chosen one of the above methods to ingest data, create indexes on the database:
This is done by modifying line 421 in app.py 

### Starting the project

1. Decide which `ws_data_producer` to use:
   - `ws_data_producer.py` for market hours to get trade records from polygon.io API
   - `ws_data_producer_demo.py` for outside market hours to generate demo trade records randomly
2. Activate the virtual environment or appropriate interpreter in a terminal.
3. Run the appropriate producer with `python ws_data_producer.py` or `python ws_data_producer_demo.py` in a separate terminal.
4. If you are using data method 3, make sure the data importing process is completed and modify the code in `app.py` to use that method and set index on database or not.
5. In a separate terminal, run the Flask server with `python app.py`.

You should be prompted in the terminal with the localhost address of the web server, where you can view the project.

## Conclusion

In summary, to start the project:

1. Prepared any setup needed
2. choosing the right data method and producer method
3. activate the venv or appropriate interpreter, usually two separate terminals are needed
4. run the appropriate producer with python ...producer.py on one terminal
5. run the flask server with python app.py on another terminal

